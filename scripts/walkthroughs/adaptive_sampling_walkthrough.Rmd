---
title: "Adaptive sampling walkthrough"
author: "TMM"
date: "2023-10-24"
output: html_document
---

```{r setup}

library(mgcv)
library(terra)
library(tidyverse)
library(sf)
library(viridis)

```


```{r initial_data}

# environmental data for raster
envdat <- rast('../../data/environmental_data_subset.tif')

# true species distribution
species_distrib_rast <- rast('../../outputs/simulated_data/true_species_distribution.tif')
species_distrib_df <- as.data.frame(species_distrib_rast, xy=TRUE)
colnames(species_distrib_df) <- c("x", "y", "presence")

```


# Introduction

This R notebook accompanies figure XX in the paper 'Adaptive sampling in ecology: current practice and future opportunities'. Here, we aim to demonstrate how adaptive sampling can be used in an ecological setting. For this, we take the case of species distribution models, where we are aiming to improve our knowledge of species' distributions.

This will follow several steps:

0. Generation of initial data
1. Defining a criterion
1a. Empirical
1b. Model-based
2. Selection of new sampling occasions
2a. Optimised
2b. Independent draws
3. Sampling activity
- Rounds vs batches


# Adaptive sampling

## Step 0. Generation of initial data

For any adaptive sampling programme, we first need some initial data on which we can base our further sampling. This is code is located in `/scripts/processing/simulate_species.R` and uses some environmental variables to generate the true distribution of a species. We then sample this true species distribution according to the suburban distribution of GB, mimicking real life where people tend to record close to their homes.

```{r load_species_data}

species_records <- read.csv("../../outputs/simulated_data/sampled_species_distrib.csv")[,-1]

# define observations
species_records$observations <- 1

head(species_records)

```

## Step 1. Definition of a criterion

### Step 1a. Empirical criterion

An empirical criterion involves using only the data to determine locations for further sampling. In this case, we will identify regions that have not yet been sampled. In the code below, we convert our species records into a 1km binary raster format for presences (`1`) and absences (`0`). This creates a raster map of the species' distribution which will be our *empirical sampling layer*.


```{r empirical}

# convert species records to raster
species_rast <- rasterize(x = as.matrix(species_records[,1:2]), y = envdat[[1]], 
                          values = 1, background = 0)
species_rast_gb <- mask(species_rast, envdat[["elev"]]) # mask to GB

# Unvisited locations are any 0s!
emp_criterion_absences <- empirical_criterion[empirical_criterion$observations == 0,]

## visualise
empirical_criterion <- as.data.frame(species_rast_gb, xy = TRUE)
colnames(empirical_criterion) <- c('x', 'y', 'observations')
# head(empirical_df)

ggplot(empirical_criterion, aes(x,y, fill = factor(observations))) +
  geom_tile() +
  scale_fill_manual(name = '', labels = c("No records", "Observation"),
                    values = c("#E69F00", "#009E73")) +
  
  theme_bw()

```


### Step 1b. Model-based criterion

In a model-based adaptive sampling criterion, further sampling is based on some aspect of a model. Here, we will model the species distribution as a function of several environmental variables using GAMs. Then we will use the standard error as our measure of uncertainty on which to base further sampling. 

### Pseudoabsences

A key consideration in SDM of presence-only data is the choice of method to get pseudoabsences. This requires careful thought but here, we choose to use a random background approach as we are not interested in its effect on model performance. We will use the layer above to generate an equal number of pseudoabsences to the number of presences.

```{r pseudoabsences}

# get all locations with no records
no_records <- empirical_criterion[empirical_criterion$observations==0,]

# randomly sample
psedoabs_index <- sample(1:nrow(no_records), size = sum(empirical_criterion$observations==1))

# extract pseudoabsences
pseudoabs <- no_records[psedoabs_index,]

# bind to observations
speciesobs_df <- rbind(species_records, pseudoabs)

# visualise
ggplot(speciesobs_df, aes(x, y, col = factor(observations))) +
  geom_point(size = 0.2) +
  scale_colour_manual(name = '', labels = c("Pseudoabsences", "Presences"),
                      values = c("#E69F00", "#009E73")) +
  
  theme_bw()

```

#### Modelling

Model data and predict for GB

```{r modelling}

## get environmental data for each observation -- extract() from envdat
# choose the variables used to simulate the species and a few others

# extract data
recsdf <- cbind(speciesobs_df, 
                terra::extract(envdat, speciesobs_df[1:2], 
                               xy = FALSE, method = "simple"))
head(recsdf)

# model - simple model with few explanatory variables
gammod <- gam(observations ~ s(impr_grass) +
                s(elev) + 
                s(bio_1),
              family = 'binomial',
              data = recsdf)
summary(gammod)
plot(gammod)

# convert environmental raster to data frame
edatdf <- as.data.frame(envdat[[c("impr_grass", "elev", "bio_1")]],
                        na.rm = TRUE,
                        xy = TRUE)

# create a new x variable
newx <- edatdf[, c("x", "y", "impr_grass", "elev", "bio_1")]

# predict onto environment
newy <- predict(gammod, 
                newx,
                type = "response",
                se.fit = TRUE)

modelbased_criterion <- na.omit(cbind(newx, newy))


```


#### Extracting uncertainty

```{r standard error}

# probability of presences
ggplot(modelbased_criterion, aes(x, y, fill = fit)) +
  geom_tile() +
  scale_fill_viridis_c(name = "Probability of presence") +
  
  theme_bw()

# standard error 
ggplot(modelbased_criterion, aes(x, y, fill = (se.fit))) +
  geom_tile() +
  scale_fill_viridis_c(name = "Standard error") +
  
  theme_bw()


```


## Step 2. Selection of new sampling occasions

Important to choose the number of new locations versus number of batches. We're going to choose 750 observations

### Step 2a. Optimised

To do this, we are going to do a form of distance sampling. We create a 20km grid over the whole of GB and then sample a single point from within each of these grid cells. 


```{r empirical_optimised}

# covert empriical criterion absences to a raster - all absences
empabsr <- terra::rasterize(as.matrix(emp_criterion_absences[,1:2]), envdat[[1]])

# sample many points from this raster
samp <- spatSample(x = empabsr, size = 5000, xy = TRUE, na.rm = TRUE, method = "random")
samp_sf <- st_as_sf(samp, coords = c("x", "y"), crs = 27700)

# make a hexagonal grid over the sample - 20km 
gdf <- st_make_grid(samp_sf$geometry, cellsize = 20000, square = FALSE)

# loop through each grid cell and select a a single observation within each hexagonal grid
outdf <- data.frame()

for(i in 1:length(gdf)) {
  
  if(i%%100==0) print(i)
  
  # check if grid cell contains anything
  polyofinterest <- st_contains(gdf[i], samp_sf, sparse = FALSE)
  
  # if nothing skip to next one
  if(sum(polyofinterest)==0) next
  
  # get the points within the polygon
  points_within <- st_filter(samp_sf, gdf[i])
  
  # randomly sample one from the two
  pw_ind <- sample(1:nrow(points_within), size = 1)
  
  # store the point in the output dataframe
  outdf <- rbind(outdf, points_within[pw_ind,])
  
}

# select a random sample of 750 from these points - the desired number of locations
final_sample_ind <- sample(1:nrow(outdf), size=750)
empirical_optimised_records <- outdf[final_sample_ind,]

# plot
plot(empabsr)
plot(gdf, add = TRUE)
plot(empirical_optimised_records, add = TRUE, pch = 19, cex = 0.5)


```

should probably create a grid over the whole area and select the points from within each of those grid cells


```{r model-based_optimised}

## make grid over GB

# covert model-based criterion absences to a raster - all absences
uncertrast <- terra::rasterize(as.matrix(modelbased_criterion[,1:2]), envdat[[1]], 
                               values = modelbased_criterion$se.fit)
plot(uncertrast)

modcrit_dfsub <- modelbased_criterion[,c("x", "y", "se.fit")]

uncertsf <- st_as_sf(modcrit_dfsub, coords = c("x", "y"), crs = 27700)

uncertgrid <- st_make_grid(uncertsf$geometry, cellsize = 20000, square = FALSE)

# order according to decreasing uncertainty - se.fit
uncertsf <- uncertsf[order(uncertsf$se.fit,
                           decreasing = TRUE), ]

# select the top 1000
uncertsf_top <- uncertsf#[1:100000,]

# plot
plot(uncertrast)
plot(uncertgrid, add = TRUE)
plot(uncertsf_top, col = "red", pch = 19, add = TRUE)

uncertsftoedit <- uncertsf_top
uncertoutdf <- data.frame()

i <- 1
while(i<751) {
  # for(i in 1:1000){
  
  if(i%%50==0) print(i)
  
  # get the highest uncertainty point
  highest_uncert <- uncertsftoedit[1,]
  # print(highest_uncert)
  
  # store that point
  uncertoutdf <- rbind(uncertoutdf, highest_uncert)
  
  # remove the highest point from the data frame
  uncertsftoedit <- uncertsftoedit[-1,]
  
  # # find the grid cell(s) the highest point is in or if it touches one or 
  # # all if it touches more than one grid
  # highgridcellind <- st_within(highest_uncert, uncertgrid)
  # highgridcellind_touch <- st_touches(highest_uncert, uncertgrid)
  # highgridcellind_intersects <- st_intersects(highest_uncert, uncertgrid)
  # highgridcellind_cross <- st_crosses(highest_uncert, uncertgrid)
  # highgridcellind_overlap <- st_overlaps(highest_uncert, uncertgrid)
  # highgridcellind_covered <- st_covered_by(highest_uncert, uncertgrid)
  # 
  # # combine two methods of selecting grid cell
  # highgridcellind <- unique(c(unlist(highgridcellind), unlist(highgridcellind_touch),
  #                             unlist(highgridcellind_intersects), unlist(highgridcellind_cross),
  #                             unlist(highgridcellind_overlap), unlist(highgridcellind_covered)))
  # 
  # # the grid with the highest uncertainty in it
  # highgrid <- uncertgrid[c(highgridcellind)]
  # 
  # # find all other points within that grid cell
  # points_contained <- unlist(st_contains(highgrid, uncertsftoedit))
  
  # find all points within x distance of highest uncert
  points_contained <- unlist(st_is_within_distance(highest_uncert, uncertsftoedit,
                                                   dist = 20000))
  
  if(length(points_contained)>0){
    # remove those points from the uncertainty dataframe 
    uncertsftoedit <- uncertsftoedit[-points_contained,]
  }
  
  i <- i+1
}


plot(uncertrast)#, pch = 19)
# plot(uncertgrid, add = TRUE)
plot(uncertoutdf, col = "red", pch = 19, cex= 0.5, 
     add = TRUE)

## top 750 uncertainty locations
plot(uncertrast)#, pch = 19)
plot(highgrid, add = TRUE)
plot(uncertsftoedit[points_contained,], col = 'black', add = TRUE, pch = 19, cex = 0.5)
plot(highest_uncert, col = "red", add = TRUE, pch = 19, cex = 0.5)
plot(highgrid, add = TRUE)
plot(uncertsftoedit, col = "yellow", add = TRUE, pch = 19, cex = 0.5)


### has it worked?!?!

```


### Step 2b. Independent draws

```{r empirical_independent_draws}

# unvisited areas
emp_critind <- sample(1:nrow(emp_criterion_absences), 750) ## how many new locations are visited

# New locations visited
emp_indepdraw_new_locs <- emp_criterion_absences[emp_critind,]

# plot against true distribution
ggplot() +
  geom_tile(data = species_distrib_df, aes(x,y, fill = factor(presence))) +
  geom_point(data = species_records, aes(x,y, colour = "original records"), size = 0.5) +
  geom_point(data = emp_indepdraw_new_locs, aes(x,y, colour = "new visits"), size = 0.5) +
  scale_colour_manual(values = c("blue", "green"), name = "") +
  scale_fill_manual(name = '', labels = c("Absent", "Present"),
                    values = c("#E69F00", "#009E73")) +
  
  theme_bw()

```

Pick the 750 locations with the highest uncertainty

```{r model-based_independent_draws}

head(modelbased_criterion)

sorted_data <- modelbased_criterion[order(modelbased_criterion$se.fit,
                                          decreasing = TRUE), ]

top_uncert <- sorted_data[1:750, c("x", "y")]

# standard error + top error
ggplot() +
  geom_tile(data=modelbased_criterion, aes(x, y, fill = (se.fit))) +
  geom_point(data=top_uncert, aes(x,y, colour = "new visits"), size = 0.5) +
  scale_fill_viridis_c(name = "Standard error") +
  scale_colour_manual(name = "", values = "orange") +
  
  theme_bw()


```




need to compare against the true species distribution to see whether new observations are made --- Maybe next step because it's not technically part of the adaptive sampling process (Maybe in the rounds vs batches section)

