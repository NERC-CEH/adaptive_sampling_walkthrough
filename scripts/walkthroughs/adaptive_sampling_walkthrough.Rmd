---
title: "Adaptive sampling walkthrough"
date: ""
output: html_document
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

set.seed(123)

```


```{r packages, include = FALSE}

library(mgcv)
library(terra)
library(tidyverse)
library(tidyterra)
library(sf)
library(viridis)

source("../../scripts/functions/as_functions.R")

```


```{r initial_data, include = FALSE}

# environmental data for raster
envdat <- rast('../../data/environmental_data_subset.tif')

# true species distribution
species_distrib_rast <- rast('../../outputs/simulated_data/true_species_distribution.tif')
true_species_distrib_df <- as.data.frame(species_distrib_rast, xy=TRUE)
colnames(true_species_distrib_df) <- c("x", "y", "presence")
plot(species_distrib_rast, main = "True species distribution")

```


```{r choose_nlocs_dist, echo = FALSE}

# choose number of new locations to sample and distance between them
nlocs <- 1200
dist_apart <- 10000
n_rounds <- 4

write = TRUE

```


# Introduction

This R notebook accompanies Box 1 in the paper 'Adaptive sampling in ecology: key challenges and future opportunities'. Here, we aim to demonstrate how adaptive sampling can be used in an ecological setting. For this, we take the case of a monitoring programme that is aiming to improve our knowledge of a species' distribution.

This will follow several steps:

1. Data - Generate initial data
2. Defining a criterion
- 2a. Empirical
- 2b. Model-based
3. Selection of new sampling occasions
- 3a. Optimised
- 3b. Independent draws
4. Sampling activity
- Rounds vs batches

In this example, we will be aiming to improve our knowledge of the distribution of the hipporhinostricow, _Spikus milligani_. This elusive species is generally found by carrying out night-time surveys, when the easiest way to find it is through its loud whistle-type call. It is easily identifiable through its cow-like body and legs, its long neck and a rhinocerous-like horn. It is found across the very edge of continental Western Europe and is thought to be slowly increasing its range northwards and eastwards. It has so far been found most of the way along the western coast of Great Britain (GB), but we do not believe that we have sampled its entire range.

# Adaptive sampling

## Step 1. Generate initial data

For any adaptive sampling programme, we first need some initial data on which we can base our further sampling. As discussed in the paper, these data can take many forms, from the results of professional surveys through to expert knowledge. Importantly, these initial data do not necessarily need to be of the same type and structure as the data we wish to generate. For this example we will assume that the records of the hipporhinostricow have been sampled opportunistically, i.e. these data are not from professional surveys. Therefore, our data will only have information on presences rather than absences. 

The code to simulate this species' distribution is located in `/scripts/processing/simulate_species.R`. We simulated the species' true distribution and then sampled it probabilistically. The probabilistic sampling was biased according to the distribution of urban and suburban habitat across GB, and latitude, with more samples from the southern parts of GB. This mimics the real-life situation where people tend to record wildlife close to their homes and that there are generally more records from areas with a higher population density. This produced the recorded distribution of the hipporhinostricow (figure 1).

```{r load_species_data, echo = FALSE}

species_records <- read.csv("../../outputs/simulated_data/sampled_species_distrib.csv")[,-1]

# define observations
species_records$observations <- 1

### create GB outline
gboutline <- envdat[["elev"]]
values(gboutline)[!is.na(values(gboutline))] <- 1
gboutline <- as.polygons(gboutline)
# plot(gboutline)


initial_records_plot <- 
  ggplot() +
  geom_sf(data = gboutline) +
  geom_point(data = species_records, aes(x,y)) +
  coord_sf(crs = 27700) +
  theme_void()

initial_records_plot +
  theme_bw() +
  labs(caption = "Figure 1 The recorded distribution of the\nhipporhinostricow in Great Britain") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write){
  ggsave(initial_records_plot,
         file = "../../outputs/plots/initial_records.png",
         height = 5, width = 4)
}

```

## Step 2. Definition of a criterion

The second step in the adaptive sampling process is to define a criterion, which is used to decide which elements of the sampling design to alter. It is from this layer that we choose locations in which to carry out further sampling. There are many ways in which the initial data can be used, which depend on the question of interest. Here, we provide two examples, an empirical method and a model-based method. See the paper for more information.

### Step 2a. Empirical criterion

An empirical criterion uses only the raw data to determine locations for further sampling. In this example, we identify regions that have not yet been sampled. In the code below, we convert our species records into a 1km binary grid of presences (`1`) and absences (`0`). This can be used to create a map of the species' distribution. The absences in this distribution map will be our *empirical sampling criterion* (figure 2).


```{r empirical}

# convert species records to raster format
species_rast <- rasterize(x = as.matrix(species_records[,1:2]), y = envdat[["elev"]], 
                          values = 1, # give presences 1
                          background = 0) # give absences 0

# mask to GB using elevation data layer - sets sea to NA
species_rast_gb <- mask(species_rast, envdat[["elev"]]) 

# convert back to a data frame for sampling and plotting  
species_sampled_distrib_df <- as.data.frame(species_rast_gb, xy = TRUE)
colnames(species_sampled_distrib_df) <- c('x', 'y', 'observations')

# define the criterion layer - unvisited areas are 0
emp_criterion_absences <- species_sampled_distrib_df[species_sampled_distrib_df$observations == 0,]

```


```{r empirical_plot, echo = FALSE}

# plot the distribution
obssp_dsitrib <- ggplot(species_sampled_distrib_df, 
                        aes(x,y, fill = factor(observations))) +
  geom_raster() +
  scale_fill_manual(name = "", 
                    labels = c("No records", "Records"),
                    values = c("#E69F00", "#009E73")) +
  coord_sf(crs = 27700) +
  
  theme_void() +
  theme(text = element_text(size = 30))

obssp_dsitrib +
  theme_bw() +
  labs(caption = "Figure 2 The empirical sampling criterion containing information\nabout hipporhinostricow presences and absences across GB") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write) {
  
  ggsave(obssp_dsitrib, 
         file = "../../outputs/plots/empirical_criterion.png",
         height = 6,width = 5)
  
}

```


### Step 2b. Model-based criterion

In a model-based approach to adaptive sampling, the initial data are used to create a model, sampling is then based on optimising some feature of this model. Here, we create a species distribution model (SDM) of the hipporhinostricow as a function of several environmental variables using a Generalised Additive Model (GAM). We then extract the standard error of the model predictions to use as our measure of model-based uncertainty. This creates our *model-based criterion*.

#### Pseudoabsences

Because our data on the distribution of the hipporhinostricow were collected opportunistically, we don't have any definitive information about absences. Therefore, we need to generate pseudoabsences before running our models. The choice of method to generate pseudoabsences is important and there is a wealth of literature about how to do this depending on your question of interest. For simplicity, we choose to use a random background approach as we are not interested in the effect of pseudoabsence generation method on model performance (which is likely to be significant). We will randomly sample the same number of points as there were presences from all of the locations in which there are no current records (figure 3).

```{r pseudoabsences}

# randomly sample from the empirical criterion layer - equal number as number of presences
psedoabs_index <- sample(1:nrow(emp_criterion_absences), 
                         size = sum(species_sampled_distrib_df$observations==1))

# extract pseudoabsences
pseudoabs <- emp_criterion_absences[psedoabs_index,]

# bind back to observations
speciesobs_df <- rbind(species_records, pseudoabs)

```


```{r pseuodabsences_plot, echo=FALSE}

# visualise
ggplot(speciesobs_df, aes(x, y, col = factor(observations))) +
  geom_point(size = 0.2) +
  coord_sf(crs = 27700) +
  scale_colour_manual(name = '', labels = c("Pseudoabsences", "Presences"),
                      values = c("#E69F00", "#009E73")) +
  
  theme_bw() +
  labs(caption = "Figure 3 The presences and pseudoabsences of\nthe hipporhinostricow in GB used for modelling") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

```

#### Modelling

We fit a binomial GAM using the presences and pseudoabsences shown in figure 3. We model this with four explanatory variables fitted as splines: the percentage of improved grassland, annual mean temperature, annual precipitation and a spatial spline which combines the x and y coordinates. From this model we then plot the prediction and standard error back onto a map of GB (figures 4 and 5). The standard error, as a measure of model uncertainty, is the model-based criterion that we will use to determine subsequent sampling (figure 5). Targeting regions of high model uncertainty could be valuable for improving model performance and hence our ability to draw inference about the distribution of the hipporhinostricow.

```{r modelling}

# extract environmental data for all observations
recsdf <- cbind(speciesobs_df, 
                terra::extract(envdat, speciesobs_df[1:2], 
                               xy = FALSE, method = "simple"))

# model - simple model with few explanatory variables
gammod <- gam(observations ~ s(impr_grass) +
                s(bio_1) +
                s(bio_12) +
                s(x,y),
              family = 'binomial',
              data = recsdf)
summary(gammod)
# plot(gammod)

# convert environmental raster to a data frame for prediction
edatdf <- as.data.frame(envdat[[c("impr_grass", "elev", "bio_1", "bio_12")]],
                        na.rm = TRUE,
                        xy = TRUE)

# create a new x variable
newx <- edatdf[, c("x", "y", "impr_grass", "elev", "bio_1", "bio_12")]

# predict onto environment
newy <- predict(gammod, 
                newx,
                type = "response",
                se.fit = TRUE)

# create the model based criterion data frame
modelbased_criterion <- na.omit(cbind(newx, newy))

```

#### Extracting uncertainty

Here, we plot the predicted probability of presence (figure 4) and the standard error of the model (figure 5). The standard error is our model-based uncertainty criterion which we will use to determine future sampling locations.

```{r standard error, echo = FALSE}

# probability of presences
ggplot(modelbased_criterion, aes(x, y, fill = fit)) +
  geom_tile() +
  coord_sf(crs = 27700) +
  scale_fill_viridis_c(name = "Probability of presence") +
  
  theme_bw() +
  labs(caption = "Figure 4 The predicted distribution of the\nhipporhinostricow in Great Britain") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

# standard error 
model_based_crit_plot <- ggplot(modelbased_criterion, 
                                aes(x, y, fill = log(se.fit))) +
  geom_raster() +
  scale_fill_viridis(name = "Standard\nerror", 
                     end = 0.9,
                     labels = c("Low", "High"),
                     breaks = c(quantile(log(modelbased_criterion$se.fit), probs = c(0.2)),
                                quantile(log(modelbased_criterion$se.fit), probs = c(0.8)))) +
  coord_sf(crs = 27700) +
  
  theme_void() +
  theme(text = element_text(size = 30))

model_based_crit_plot +
  theme_bw() +
  labs(caption = "Figure 5 The standard error of the predicted distribution\nof the hipporhinostricow in Great Britain") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write) {
  
  ggsave(model_based_crit_plot, 
         file = "../../outputs/plots/modelbased_criterion.png",
         height = 6,width = 5)
  
}


```


## Step 3. Selection of new sampling occasions

Once the criterion has been defined, we can then use it to choose new sampling locations. There are many approaches that can be used to do this. Here, we provide examples of two methods which broadly lie at opposite ends of a spectrum of possible approaches. We apply these methods to both our empirical and model-based criterions. 

We have chosen to sample `r (nlocs)` new locations to look for the hipporhinostricow.
We first use an optimised method and then use an empirical method to sample from our two criterions. For more information about the merits of different sampling methods, see the paper.

### Step 3a. Optimised

#### Empirical method - optimised

First, we will sample our empirical criterion using an optimised approach. As a reminder, our empirical criterion is a spatial layer that identifies all unvisited locations. To sample from this in an optimised way, we select a random location from this criterion. We then remove all other locations within `r (dist_apart)`m of it and sample another point. Drawing samples that are a minimum distance from each other could be beneficial by preventing locations that are very close together from being visited. We do this until `r (nlocs)` locations are sampled across all of GB (figure 6). In some of the subsequent figures only Scotland is shown to make the differences in sampling methods obvious. All sampling and modelling is done across all of GB.    


```{r empirical_optimised, cache = TRUE}

# convert empirical criterion metric (all absences) to an sf object
emp_absences <- st_as_sf(emp_criterion_absences[,1:2], coords = c("x", "y"), crs = 27700)

# save uncertainty layer into a new file that can have points removed
emp_abs_sftoedit <- emp_absences
empabsoutdf <- data.frame() # data frame for storage

i <- 1
while(i<=nlocs) {
  
  # if(i%%50==0) print(i)
  
  # sample a random point from all absences
  sampled_point_ind <- sample(1:nrow(emp_abs_sftoedit), size = 1)
  sampled_point <- emp_abs_sftoedit[sampled_point_ind,]
  
  # store that point
  empabsoutdf <- rbind(empabsoutdf, sampled_point)
  
  # remove that locationS from the data frame
  emp_abs_sftoedit <- emp_abs_sftoedit[-sampled_point_ind,]
  
  # find all points within dist_apart of this point
  absence_points_nearby <- unlist(st_is_within_distance(sampled_point, emp_abs_sftoedit,
                                                        dist = dist_apart))
  
  if(length(absence_points_nearby)>0){
    # remove those points from the absences dataframe 
    emp_abs_sftoedit <- emp_abs_sftoedit[-absence_points_nearby,]
  }
  
  i <- i+1
}

```


```{r empirical_optimised_plot, echo=FALSE}

# plot
emp_optim <- ggplot() +
  geom_raster(data = species_sampled_distrib_df, aes(x,y, fill = factor(observations))) +
  scale_fill_manual(name = '', labels = c("Absences", "Observations"),
                    values = c("#E69F00", "#009E73")) +
  geom_sf(data = empabsoutdf, aes(colour = "New recording\nlocations")) +
  coord_sf(crs = 27700, expand = FALSE) +
  scale_colour_manual(name = "", values = "black") +
  # ylim(0, 350000) +
  ylim(622500, 980000) +
  xlim(45000, 425000) +
  
  theme_void() +
  theme(text = element_text(size = 25)) +
  guides(fill = "none", colour = "none")

emp_optim +
  theme_bw() +
  labs(caption = "Figure 6 Optimised selection of empirical sampling locations") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write) {
  
  ggsave(emp_optim, 
         file = "../../outputs/plots/emp_optim_selection.png",
         height = 5,width = 5)
  
}


```


#### Model-based - optimised

We choose to optimise our sampling of the model-based criterion layer in the same way as for the empirical later. The model-based criterion is a map of standard error (uncertainty) of model predictions that was run using the initial data. To do this, we select the location in GB that has the highest model uncertainty. Then, we  remove all other locations within `r (dist_apart)`m of this location, and then sample the location with the next highest uncertainty. We repeat this until `r (nlocs)` have been sampled (figure 7).

```{r model-based_optimised, cache = TRUE}

# get only uncertainty and coordinates from model based criterion
modcrit_dfsub <- modelbased_criterion[,c("x", "y", "fit", "se.fit")]

# convert to sf
uncertsf <- st_as_sf(modcrit_dfsub, coords = c("x", "y"), crs = 27700)

# order the uncertainty layer according to decreasing uncertainty - se.fit
uncertsf <- uncertsf[order(uncertsf$se.fit,
                           decreasing = TRUE), ]

# save uncertainty layer into a new file that can have points removed
uncertsftoedit <- uncertsf
uncertoutdf <- data.frame() # data frame for storage

i <- 1
while(i<=nlocs) {
  
  # if(i%%50==0) print(i)
  
  # get the highest uncertainty point
  highest_uncert <- uncertsftoedit[1,]
  # print(highest_uncert)
  
  # store that point
  uncertoutdf <- rbind(uncertoutdf, highest_uncert)
  
  # remove the highest point from the data frame
  uncertsftoedit <- uncertsftoedit[-1,]
  
  # find all points within x distance of highest uncert
  uncert_points_nearby <- unlist(st_is_within_distance(highest_uncert, uncertsftoedit,
                                                       dist = dist_apart))
  
  if(length(uncert_points_nearby)>0){
    # remove those points from the uncertainty dataframe 
    uncertsftoedit <- uncertsftoedit[-uncert_points_nearby,]
  }
  
  i <- i+1
}

```


```{r model-based_optimised_plot, echo = FALSE}

# plot
model_optim <- ggplot() +
  geom_raster(data = modelbased_criterion, aes(x, y, fill = log(se.fit))) +
  scale_fill_viridis_c(name = "Standard error", 
                       end = 0.9) +
  geom_sf(data = uncertoutdf, aes(colour = "New recording\nlocations")) +
  coord_sf(crs = 27700, expand = FALSE) +
  scale_colour_manual(name = "", values = "black") +
  # ylim(0, 350000) +
  ylim(622500, 980000) +
  xlim(45000, 425000) +
  
  theme_void() +
  theme(text = element_text(size = 25)) +
  guides(fill = "none", colour = "none")

model_optim +
  theme_bw() +
  labs(caption = "Figure 7 Optimised selection of model-based sampling locations") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write) {
  
  ggsave(model_optim, 
         file = "../../outputs/plots/modelbased_optim_selection.png",
         height = 5,width = 5)
  
}

```


### Step 3b. Independent draws

The alternative to optmising our choice of sampling locations is to select each location independently from one another. This means that the sampling of one location is not dependent on any of the other locations being sampled.

#### Empirical - independent draws

For our independent draws method we randomly select `r (nlocs)` locations from the empirical criterion (figure 8).

```{r empirical_independent_draws}

# Randomly sample from unvisited areas
emp_critind <- sample(1:nrow(emp_criterion_absences), nlocs)

# New locations visited
emp_indepdraw_new_locs <- st_as_sf(emp_criterion_absences[emp_critind,], 
                                   coords = c("x", "y"), crs = 27700)

```


```{r empirical_independent_draws_plot, echo=FALSE}

# plot
empindep_draws <- ggplot() +
  geom_raster(data = species_sampled_distrib_df, aes(x,y, fill = factor(observations))) +
  # geom_point(data = species_records, aes(x,y, colour = "original records"), size = 0.5) +
  geom_sf(data = emp_indepdraw_new_locs, 
          aes(colour = "New recording\nlocations")) +
  coord_sf(crs = 27700, expand = FALSE) +
  scale_colour_manual(values = c("black"), name = "") +
  scale_fill_manual(name = '', labels = c("Absences", "Observations"),
                    values = c("#E69F00", "#009E73")) +
  # ylim(0, 350000) +
  ylim(622500, 980000) +
  xlim(45000, 425000) +
  
  theme_void() +
  theme(text = element_text(size = 25)) +
  guides(fill = "none", colour = "none")

empindep_draws +
  theme_bw() +
  labs(caption = "Figure 8 Independent draws of empirical sampling locations") +
  theme(text = element_text(size = 18),
        plot.caption.position = "plot")

if(write) {
  
  ggsave(empindep_draws, 
         file = "../../outputs/plots/empirical_indep_selection.png",
         height = 5,width = 5)
  
}

```

#### Model-based - indpendent draws

For the model-based sampling method, we choose the `r (nlocs)` locations with the highest uncertainty (figure 9).

```{r model-based_independent_draws}

# order all locations by decreasing standard error - highest uncertainty first
sorted_data <- modelbased_criterion[order(modelbased_criterion$se.fit,
                                          decreasing = TRUE), ]

top_uncert <- st_as_sf(sorted_data[1:nlocs, c("x", "y")], 
                       coords = c("x", "y"), crs = 27700)

```


```{r model-based_independent_draws_plot, echo=FALSE}

# standard error + top error
model_indep <- ggplot() +
  geom_raster(data=modelbased_criterion, aes(x, y, fill = log(se.fit))) +
  geom_sf(data=top_uncert, aes(colour = "New recording\nlocations")) +
  # geom_sf(data = gboutline, fill = NA) +
  coord_sf(crs = 27700, expand = FALSE) +
  scale_fill_viridis_c(name = "Standard error", 
                       end = 0.9) +
  scale_colour_manual(name = "", values = "black") +
  # ylim(0, 350000) +
  ylim(622500, 980000) +
  xlim(45000, 425000) +
  
  theme_void() +
  theme(text = element_text(size = 25)) +
  guides(fill = "none", colour = "none")

model_indep +
  theme_bw() +
  labs(caption = "Figure 9 Independent draws of model-based sampling locations") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write) {
  
  ggsave(model_indep, 
         file = "../../outputs/plots/model_indep_selection.png",
         height = 5, width = 5)
  
}

```


## Step 4. Rounds vs batch size

Adaptive sampling is an inherently iterative process. This means that decisions need to be made about the number of rounds over which adaptive sampling will occur and the number of samples taking during each round. This decision will be study-specific. For example, if data collection involved a lot of organisation and a trip overseas, it might be that it's only possible to undertake a single collection incident. In other cases, it might be that we are able to carry out sampling over several iterations, with the criterion recalculated at each step.

As an example, here we carry out four rounds adaptive sampling, with a batch size of `r (round(nlocs/n_rounds))`. The function below runs an optimised model-based adaptive sampling design, as outlined above. In each step it samples `r (round(nlocs/n_rounds))` locations that are `r (dist_apart)`m apart and reruns the GAM using both the initial and new data. The results of this are shown in Figure 10.

```{r rounds_and_batches, cache = TRUE}

# Model rounds and batches
as_rounds <- adaptive_sampling_rounds(
  
  # number of rounds
  nrounds = n_rounds,
  
  # number of locations in total
  total_number_locs = nlocs,
  
  # uncertainty layer from first model
  modelbased_crit_sf = uncertsf,
  
  # the initial species records
  initial_species_records = species_records,
  
  # distance between records to maintain
  distance_apart = dist_apart,
  
  # true species distribution - for checking whether new samples find the species
  true_spp_distrib = species_distrib_rast
)

```


```{r plotting rounds, echo = FALSE, fig.width=7, fig.height=7}

## for plotting need to add the initial uncertainty to the data frame and remove the fourth round of sampling. First round of adaptive sampling was based on the initial model's uncertainty and there is no fifth round

# get the initial uncertainty layer as dataframe
initial_uncert_data <- data.frame(x = st_coordinates(uncertsf)[,1],
                                  y = st_coordinates(uncertsf)[,2],
                                  fit = uncertsf$fit,
                                  se.fit = uncertsf$se.fit, 
                                  round = 'initial')

# bind to the new uncertainty layers
all_uncert_data <- rbind(initial_uncert_data, as_rounds[["model_uncertainty"]])

# remove round #4 - no fifth round of adaptive sampling
all_uncert_data <- all_uncert_data[all_uncert_data$round != 4,]

# convert the round number to factor and rename
new_locations <- as_rounds[["all_adaptive_locations"]]

# rename to rounds
new_locations$round <- factor(new_locations$round)
all_uncert_data$round <- factor(all_uncert_data$round, levels = c("initial", 1, 2, 3))

levels(new_locations$round) <- c("Round 1","Round 2",
                                 "Round 3","Round 4")
levels(all_uncert_data$round) <- c("Round 1","Round 2",
                                   "Round 3","Round 4")

# plot
model_round <- ggplot() +
  geom_raster(data = all_uncert_data, aes(x, y, fill = log(se.fit))) +
  scale_fill_viridis_c(name = "Standard error", 
                       end = 0.9) +
  geom_point(data = new_locations, aes(x,y), size = 0.8) +#,colour = factor(observations))) +
  coord_sf(crs = 27700, expand = FALSE) +
  # ylim(0, 350000) +
  ylim(622500, 980000) +
  xlim(45000, 425000) +
  
  theme_bw() +
  theme(text = element_text(size = 30),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        strip.text.x = element_text(size = 18, family="Calibri"),
        strip.background = element_blank()) +
  guides(fill = "none") +
  # scale_colour_manual(name = "Species\npresence", values = c("black", "grey")) +
  
  facet_wrap(~round, ncol = 2)
model_round +
  labs(caption = "Figure 10 Optimised selection of model-based sampling\nlocations spread over four rounds of adaptive sampling") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")


if(write) {
  
  ggsave(model_round, 
         file = "../../outputs/plots/round_adaptive_sampling.png",
         height = 6, width = 5)
  
}

```

As you can see, in each round new sampling locations are chosen based on the underlying model uncertainty whilst ensuring that they are at least `r (dist_apart)`m from samples in the current round and all previous rounds. In each round, the underlying uncertainty layer changes because of the new observations selected in the last round.

## New data

This adaptive sampling process results in a set of new data (figure 11). The data have been generated by sampling in the locations identified through multiple rounds of adaptive sampling. At each of the sampling locations we determined whether the hipporhinostricow was present against its true distribution (assuming perfect detectability) and kept any successful detections. In reality, successfully finding an animal in an area in which it is present will depend on its detectability and the skill of the recorder. These data can then be used for a variety of purposes, from further modelling to implementing conservation measures.

```{r new records, echo = FALSE}

new_records_plot <- 
  ggplot() +
  geom_sf(data = gboutline) +
  geom_point(data = new_locations[new_locations$observations==1,], aes(x,y), colour="darkgreen") +
  coord_sf(crs = 27700) +
  theme_void()

new_records_plot +
  theme_bw() +
  labs(caption = "Figure 11 New records of the hipporhinostricow\nobtained through four rounds of model-based adaptive sampling") +
  theme(text = element_text(size = 18),
        axis.text.x = element_text(angle=90, hjust=1),
        plot.caption.position = "plot")

if(write){
  ggsave(new_records_plot,
         file = "../../outputs/plots/new_records.png",
         height = 5, width = 4)
}

```

